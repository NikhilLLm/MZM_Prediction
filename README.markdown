# Majorana Zero Modes Detection via Quantum Simulation and Machine Learning

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/Framework-PyTorch-ee4c2c.svg)](https://pytorch.org/)
[![Kwant](https://img.shields.io/badge/Quantum-Kwant-green.svg)](https://kwant-project.org/)

This repository presents a **research-oriented implementation** for detecting **Majorana Zero Modes (MZMs)** in one-dimensional topological superconductors using **quantum simulations and machine learning**. The project is inspired by recent literature on ML-assisted Majorana detection and focuses on **data generation, physical feature extraction, and model interpretability**, rather than only raw classification accuracy.

> **Key emphasis:** realistic simulation pipelines, physically motivated labels, and honest analysis of when ML succeeds *and* fails.

---

## ðŸ“‘ Table of Contents

- [Scientific Motivation](#-scientific-motivation)
- [Example Data: Conductance Maps](#-example-data-conductance-maps)
- [Project Overview](#-project-overview)
- [Method 1: Wavefunction-Based Localization](#-method-1-wavefunction-based-localization-group-work)
- [Method 2: Conductance Mapâ€“Based Detection](#-method-2-conductance-mapbased-detection-my-contribution)
- [Machine Learning Models](#-machine-learning-models)
- [Results: Comprehensive Analysis](#-results-comprehensive-analysis)
- [Key Visualizations: Feature Learning](#-key-visualizations-feature-learning-quality)
- [Interpretation](#-interpretation-important)
- [Project Structure](#-project-structure)
- [Reproducibility](#-reproducibility--data-handling)
- [Reference](#-reference)

---

## ðŸ”¬ Scientific Motivation

Majorana Zero Modes are zero-energy quasiparticles emerging at the edges of topological superconductors and are central to fault-tolerant quantum computing. However, their experimental signaturesâ€”especially **zero-bias peaks (ZBPs)**â€”are often ambiguous and can be mimicked by trivial Andreev bound states (ABS).

This project explores whether **machine learning models trained on simulated quantum data** can:

* Distinguish topological vs trivial phases
* Learn physically meaningful representations
* Reveal *why* certain signatures are hard to classify

---

## ðŸ“Š Example Data: Conductance Maps

The conductance pipeline generates **differential conductance (dI/dV) maps** showing transport signatures across parameter space:

<p align="center">
  <img src="results/c1.png" alt="Example conductance map" width="650"/>
</p>

**What you're seeing:** 
- **X-axis:** Chemical potential (Î¼) - tunes the nanowire through topological phase transition
- **Y-axis:** Bias voltage (V) - energy scale for tunneling spectroscopy  
- **Color intensity:** Differential conductance (bright = high dI/dV)
- **Vertical bright features near Vâ‰ˆ0:** Zero-bias peaks that *may* indicate Majorana modes

This is **one example** from the 4000+ maps generated by the simulation pipeline.

---

## ðŸ“Œ Project Overview

Two complementary pipelines are implemented:

| Pipeline                      | What it Studies             | Data Generated                 | Purpose                          |
| ----------------------------- | --------------------------- | ------------------------------ | -------------------------------- |
| **Wavefunction-Based (BdG)**  | Eigenstates of Kitaev chain | Spectra, localization profiles | Detect edge-localized zero modes |
| **Conductance-Based (Kwant)** | Transport signatures        | 2D conductance maps (dI/dV)    | Detect ZBPs in tunneling spectra |



---

## ðŸ§ª Method 1: Wavefunction-Based Localization (Group Work)

### Physical Model

* 1D Kitaev chain (spinless p-wave superconductor)
* Parameters swept:
  * Chemical potential (Î¼)
  * Hopping (t)
  * Pairing (Î”)
  * Disorder strength (Ïƒ)
  * Chain length (L)

### Outputs

* Bogoliubovâ€“de Gennes (BdG) eigenvalues
* Eigenvectors â†’ spatial probability density
* **Edge-localization score** derived via exponential decay fits

### Role in Project

This pipeline establishes a **ground-truth physical picture** of MZMs and provides intuition for what ML should (and should not) be able to learn.

---

## âš¡ Method 2: Conductance Mapâ€“Based Detection (My Contribution)

### Simulation Setup

* Implemented using **Kwant quantum transport framework**
* Semiconductorâ€“superconductor nanowire geometry
* Swept parameters:
  * Chemical potential (Î¼)
  * Sourceâ€“drain bias (V)
* Fixed pairing, hopping, and disorder per sweep

### Data Generated

* **4,000+ conductance maps**
* Each map: 30Ã—30 grid of differential conductance (dI/dV)
* Labels assigned based on presence/absence of robust ZBP near V â‰ˆ 0

> Raw simulation data is intentionally excluded from version control due to size. Full regeneration is possible via provided scripts.

---

## ðŸ§  Machine Learning Models

### Feature Learning

* CNN and ResNet-style architectures trained directly on conductance maps
* Learned representations analyzed via **PCA** and **t-SNE**

### Classifiers

* Binary classification: Topological vs Trivial
* **Ensemble approach:** Combined ResNet + SVM predictions for improved robustness
* Models evaluated using:
  * Confusion matrices
  * ROC curves
  * Decision boundary projections in latent space

---

## ðŸ“Š Results: Comprehensive Analysis

<p align="center">
  <img src="figures/results_summary.png" alt="Complete analysis pipeline: confusion matrices, ROC curve, t-SNE embedding, Grad-CAM interpretability, support vectors, phase diagram, and feature importance" width="100%"/>
</p>

### Breakdown of Analysis Components:

| Panel | Analysis Type | Key Insight |
|-------|---------------|-------------|
| **(a) ResNet Confusion Matrix** | Classification Performance | 82% trivial recall, 68% topological recall - balanced performance |
| **(b) SVM Confusion Matrix** | Feature-based Classification | 100% trivial identification when using ResNet features |
| **(c) ROC Curve** | Model Discrimination | AUC = 0.49 reveals fundamental detection difficulty |
| **(d) t-SNE + Boundary** | Feature Space Structure | Continuous manifold â†’ phase transition is gradual, not discrete |
| **(e1-e2) Grad-CAM** | Model Interpretability | **Network attention on edge state regions validates physics learning** |
| **(f1-f2) Support Vectors** | Decision Boundary | Topological vs trivial samples lie on opposing sides in conductance space |
| **(g) Phase Diagram** | Ground Truth Labels | Orange = topological phase, Purple = trivial phase |
| **(h) Feature Importance** | Hybrid Approach | CNN features (CNN_84, CNN_96) + handcrafted (Avg_Peak_Height) |

### ðŸ”‘ Critical Findings:

1. **Grad-CAM Validation (e1-e2):** The model learns to focus on **physically meaningful regions** (edge states near Î¼â‰ˆ0, Vâ‰ˆ0) rather than spurious correlations. This proves the CNN extracts physics-based features, not noise patterns.

2. **Ensemble Complementarity:** ResNet excels at spatial feature extraction while SVM finds optimal decision boundaries. Combined approach achieves better robustness than either method alone.

3. **Honest Evaluation:** The modest ROC AUC reflects **real physical ambiguity** in zero-bias peak signatures - consistent with experimental challenges in the field.

---

## ðŸŽ¯ Key Visualizations: Feature Learning Quality

### PCA of CNN Features

<p align="center">
  <img src="figures/pca_scatter.png" alt="PCA of learned features" width="450"/>
</p>

Shows partial but structured separation between topological and trivial samples. Demonstrates that CNNs learn **non-random, physically correlated features** rather than memorizing noise patterns.

---

### PCA with Decision Boundary

<p align="center">
  <img src="figures/pca_scatter_with_boundary.png" alt="PCA with decision boundary" width="450"/>
</p>

Highlights strong class overlap near phase boundaries. This is an important negative result that explains why perfect classification is impossibleâ€”the phase transition region is fundamentally ambiguous.

---

### t-SNE of Deep Features with Boundary

<p align="center">
  <img src="figures/tsne_scatter_with_boundary.png" alt="t-SNE embedding" width="450"/>
</p>

Nonlinear embedding shows curved manifolds rather than separable clusters. Consistent with known ambiguity of ZBP-based detection in experimental literature.

---

## ðŸ§  Interpretation (Important)

Key insight from this project:

> **Zero-bias peaks alone are insufficient to reliably distinguish MZMs from trivial states, even for deep learning models trained on idealized simulations.**

This aligns with modern experimental and theoretical literature and reinforces the need for:

* Multi-modal signatures
* Wavefunction-level analysis
* Physics-informed ML pipelines

The **ensemble approach combining ResNet and SVM** demonstrates how complementary models can partially address this challenge, but fundamental physical ambiguity remains near phase transitions.

---

## ðŸ—‚ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data_main.py                # Main data generation orchestration
â”‚   â”œâ”€â”€ data_processing.py          # Preprocessing and normalization
â”‚   â”œâ”€â”€ dataloader.py               # PyTorch dataset classes
â”‚   â”œâ”€â”€ kitaev_hamiltonian.py       # BdG Hamiltonian construction (group)
â”‚   â”œâ”€â”€ phases.py                   # Phase labeling and utilities
â”‚   â”œâ”€â”€ simulate_conductance...     # Kwant transport simulation (my code)
â”‚   â””â”€â”€ tda_features.py             # Topological data analysis features
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model.py                    # CNN/ResNet architectures
â”‚   â”œâ”€â”€ train.py                    # Training script
â”‚   â””â”€â”€ main_test.py                # Evaluation pipeline
â”‚
â”œâ”€â”€ figures/                         # Analysis visualizations
â”‚   â”œâ”€â”€ confusion_matrix_resnet.png
â”‚   â”œâ”€â”€ confusion_matrix_svm.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ pca_scatter.png
â”‚   â”œâ”€â”€ pca_scatter_with_boundary.png
â”‚   â”œâ”€â”€ tsne_scatter_with_boundary.png
â”‚   â””â”€â”€ results_summary.png         # Comprehensive analysis figure
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ c1.png                      # Example conductance map
â”‚   â””â”€â”€ Readme                      # Additional results documentation
â”‚
â””â”€â”€ README.md
```

---

## ðŸ” Reproducibility & Data Handling

* Simulation data stored externally (mounted drive / cloud storage)
* Paths configurable via environment variables
* All figures can be regenerated using provided scripts

**To regenerate data:**
```bash
python data/simulate_conductance.py --n_samples 4000
```

**To train models:**
```bash
python models/train.py --config configs/resnet_config.yaml
```

---

## ðŸ“š Reference

This work is inspired by:

> *Machine Learning Majorana Zero Modes* (arXiv:2310.18439)

This repository provides an **independent implementation** with custom data generation, preprocessing, and analysis.

---

**This project prioritizes scientific clarity and honest evaluation over inflated performance claims.**
